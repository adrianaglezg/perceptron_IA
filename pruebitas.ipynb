{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor vac칤o:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-7.2252e-35,  8.8982e-43,  5.6125e-01],\n",
       "        [ 5.5277e-01,  8.3338e-01,  3.2504e-01],\n",
       "        [ 9.9651e-01,  3.5166e-01,  4.4490e-01]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear un tensor vac칤o\n",
    "tensor_vacio = torch.empty(3, 3)  # 3x3 sin inicializar\n",
    "print(\"Tensor vac칤o:\")\n",
    "tensor_vacio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor aleatorio:\n",
      "tensor([[0.0999, 0.7936, 0.4332],\n",
      "        [0.1255, 0.0435, 0.9421],\n",
      "        [0.8486, 0.4453, 0.3495]])\n"
     ]
    }
   ],
   "source": [
    "tensor_random = torch.rand(3, 3)\n",
    "print(\"Tensor aleatorio:\")\n",
    "print(tensor_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13.3499, 11.1950, 16.1251],\n",
       "        [19.7878, 15.4527, 15.1269],\n",
       "        [14.4118, 19.1310, 12.5540]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_random_2 = torch.rand(3, 3) * (20 - 10) + 10\n",
    "tensor_random_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2731,  1.3950,  0.2728],\n",
      "        [-0.1344,  0.9675,  1.1878],\n",
      "        [-0.6753, -0.0292,  0.7935]])\n"
     ]
    }
   ],
   "source": [
    "tensor_normal = torch.randn(3, 3)\n",
    "print(tensor_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor de ceros:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "\n",
      "Tensor de unos:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Crear un tensor lleno de ceros o unos\n",
    "tensor_ceros = torch.zeros(3, 3)\n",
    "tensor_unos = torch.ones(3, 3)\n",
    "print(\"Tensor de ceros:\")\n",
    "print(tensor_ceros)\n",
    "print(\"\\nTensor de unos:\")\n",
    "print(tensor_unos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor personalizado:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Crear un tensor con valores personalizados\n",
    "tensor_manual = torch.tensor([[1, 2], [3, 4]])\n",
    "print(\"Tensor personalizado:\")\n",
    "print(tensor_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del tensor: torch.Size([2, 2])\n",
      "Tipo de datos: torch.int64\n",
      "Dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "# Ver la forma, el tipo de datos y el dispositivo del tensor\n",
    "print(\"Forma del tensor:\", tensor_manual.shape)\n",
    "print(\"Tipo de datos:\", tensor_manual.dtype)\n",
    "print(\"Dispositivo:\", tensor_manual.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando el dispositivo: cpu\n",
      "\n",
      "Tensor en GPU: tensor([1., 2., 3.])\n",
      "\n",
      "Resultado en GPU: tensor([2., 4., 6.])\n",
      "\n",
      "Resultado de vuelta en la CPU: tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "# Comprobar si hay una GPU disponible\n",
    "dispositivo = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Usando el dispositivo:\", dispositivo)\n",
    "\n",
    "# Crear un tensor y moverlo a la GPU\n",
    "tensor = torch.tensor([1.0, 2.0, 3.0])\n",
    "tensor_gpu = tensor.to(dispositivo)\n",
    "print(\"\\nTensor en GPU:\", tensor_gpu)\n",
    "\n",
    "# Realizar operaciones en la GPU\n",
    "resultado = tensor_gpu * 2\n",
    "print(\"\\nResultado en GPU:\", resultado)\n",
    "\n",
    "# Mover el tensor de vuelta a la CPU\n",
    "resultado_cpu = resultado.to('cpu')\n",
    "print(\"\\nResultado de vuelta en la CPU:\", resultado_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Esto debe devolver True si CUDA est치 configurado correctamente.\n",
    "# print(torch.cuda.device_count())  # N칰mero de GPUs disponibles.\n",
    "# print(torch.cuda.get_device_name(0))  # Nombre de la GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA est치 disponible: False\n",
      "Versi칩n de CUDA en PyTorch: None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA est치 disponible:\", torch.cuda.is_available())\n",
    "print(\"Versi칩n de CUDA en PyTorch:\", torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capas b치sicas en torch.nn:\n",
    "  * De procesamiento (layers)\n",
    "    * Linear\n",
    "    * Conv2d\n",
    "    * ConvTranspose2d\n",
    "    * LSTM\n",
    "    * GRU\n",
    "    * Transformer\n",
    "    * Embeeding\n",
    "  * De activaci칩n\n",
    "    * Sigmoid\n",
    "    * Tanh\n",
    "    * ReLU\n",
    "    * LeakyReLU\n",
    "    * Softmax\n",
    "  * Auxiliares\n",
    "    * Dropout\n",
    "    * MaxPool2d\n",
    "    * BatchNorm2d\n",
    "    * LocalResponseNorm\n",
    "    * Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Capas de procesamiento (layers):\n",
    "Estas capas son las principales para construir modelos y procesar datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5618, -0.4485]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Linear: Una capa completamente conectada (o densa). Realiza una transformaci칩n lineal 洧녽= 洧논洧녥^洧녢 + 洧녪  \n",
    "linear = nn.Linear(in_features=3, out_features=2)\n",
    "x = torch.tensor([[1.0, 2.0, 3.0]])\n",
    "print(linear(x))  # Salida transformada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1023, -0.2253,  0.1569],\n",
      "          [ 0.0596,  0.2316,  0.0564],\n",
      "          [ 0.1567, -0.1324, -0.0601]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Conv2d: Realiza convoluciones 2D, com칰nmente usada para procesar im치genes.\n",
    "conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\n",
    "x = torch.rand(1, 1, 5, 5)  # Lote de una imagen 5x5 con 1 canal\n",
    "print(conv(x))  # Salida convolucionada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1: Hay 1 imagen en el lote.\n",
    "- 1: Cada imagen tiene 1 canal.\n",
    "- 5x5: Cada imagen tiene un tama침o de 5칑5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1088, 0.1637, 0.7025, 0.6790, 0.9155],\n",
       "          [0.2418, 0.1591, 0.7653, 0.2979, 0.8035],\n",
       "          [0.3813, 0.7860, 0.1115, 0.2477, 0.6524],\n",
       "          [0.6057, 0.3725, 0.7980, 0.8399, 0.1374],\n",
       "          [0.2331, 0.9578, 0.3313, 0.3227, 0.0162]]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 1, 5, 5)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.8823, 0.9150, 0.3829, 0.9593, 0.3904],\n",
      "          [0.6009, 0.2566, 0.7936, 0.9408, 0.1332],\n",
      "          [0.9346, 0.5936, 0.8694, 0.5677, 0.7411],\n",
      "          [0.4294, 0.8854, 0.5739, 0.2666, 0.6274],\n",
      "          [0.2696, 0.4414, 0.2969, 0.8317, 0.1053]]]])\n"
     ]
    }
   ],
   "source": [
    "# Fijar semilla\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Crear un tensor aleatorio\n",
    "x = torch.rand(1, 1, 5, 5)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1648, -0.2234, -0.2693, -0.1059, -0.2168, -0.4298, -0.3323],\n",
      "          [-0.0511, -0.2595, -0.2959, -0.0883, -0.2194, -0.3838, -0.3837],\n",
      "          [-0.1817, -0.1986,  0.0496, -0.2829, -0.2060, -0.0917,  0.0328],\n",
      "          [-0.1686, -0.0728, -0.2638, -0.1640, -0.0364, -0.0406, -0.1803],\n",
      "          [-0.0090, -0.2742, -0.2471, -0.0399, -0.1489, -0.3335, -0.2942],\n",
      "          [-0.2075, -0.2567,  0.1085, -0.1251, -0.0994, -0.0248,  0.0501],\n",
      "          [-0.2951, -0.1609, -0.0496, -0.1198, -0.0763,  0.0017, -0.0618]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# ConvTranspose2d: Realiza una \"convoluci칩n transpuesta\", 칰til para tareas de generaci칩n (como redes generativas).\n",
    "\n",
    "trans_conv = nn.ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=3)\n",
    "x = torch.rand(1, 1, 5, 5)\n",
    "print(trans_conv(x))  # Salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.0583,  0.2664],\n",
      "         [-0.0813,  0.3540],\n",
      "         [-0.1830,  0.4887],\n",
      "         [-0.1126,  0.5353]]], grad_fn=<TransposeBackward0>), (tensor([[[-0.1126,  0.5353]]], grad_fn=<StackBackward0>), tensor([[[-0.2308,  0.7948]]], grad_fn=<StackBackward0>)))\n"
     ]
    }
   ],
   "source": [
    "# LSTM y GRU: Son redes recurrentes para datos secuenciales como texto o series temporales.\n",
    "\n",
    "lstm = nn.LSTM(input_size=3, hidden_size=2, batch_first=True)\n",
    "x = torch.rand(1, 4, 3)  # Lote con secuencia de longitud 4 y tama침o 3\n",
    "print(lstm(x))  # Salida (hidden states y hidden final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\34640\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.5384,  0.2157, -1.7964,  ..., -1.9438, -1.1512, -0.3414],\n",
      "         [-1.7553, -0.1442, -1.4974,  ..., -1.3659, -1.1200, -0.5368],\n",
      "         [-1.4746, -0.4905, -2.1174,  ..., -1.4930, -1.4591,  1.3980],\n",
      "         ...,\n",
      "         [-1.6475,  0.2279, -1.2693,  ..., -1.0877, -1.0083, -0.5880],\n",
      "         [-0.8223, -0.3251, -2.7302,  ..., -1.9302, -2.0892, -1.0509],\n",
      "         [-1.1873, -0.2369, -1.9803,  ..., -1.2396, -1.3874, -1.2241]],\n",
      "\n",
      "        [[-0.8761,  0.0370, -1.6600,  ..., -1.9562, -1.2226, -0.3018],\n",
      "         [-1.8721, -0.0072, -0.9006,  ..., -1.7600, -2.0460,  0.4842],\n",
      "         [-1.2738, -0.4549, -1.9027,  ..., -1.3531, -1.6655, -0.7205],\n",
      "         ...,\n",
      "         [-1.4730, -0.2972, -2.4643,  ..., -2.0886,  0.1140, -0.6950],\n",
      "         [-1.0263,  0.3435, -1.4559,  ..., -1.1128, -1.6498,  1.1771],\n",
      "         [-0.9823,  0.3561, -1.8716,  ..., -2.5966, -1.7647,  0.0497]],\n",
      "\n",
      "        [[-1.8313,  0.5129, -1.6190,  ..., -1.6533, -1.7796,  0.0776],\n",
      "         [-0.0791, -0.1362, -1.8106,  ..., -1.5724, -0.9193, -0.6944],\n",
      "         [-1.3071, -0.1146, -2.9079,  ..., -1.5073, -2.0617,  1.0962],\n",
      "         ...,\n",
      "         [-1.6679, -0.2473, -1.7693,  ..., -1.3500, -0.9952, -0.1832],\n",
      "         [-0.5608,  0.4589, -2.5656,  ..., -1.8523, -0.5629, -1.3542],\n",
      "         [-1.0736,  0.4304, -2.3122,  ..., -1.6015, -1.8140, -0.3065]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9136,  0.4610, -0.7765,  ..., -2.4527, -0.4682,  0.5035],\n",
      "         [-0.7193, -0.8649, -2.1760,  ..., -1.3580, -1.9193, -0.6354],\n",
      "         [-1.8024, -0.4882, -1.7152,  ..., -1.3184, -1.5677,  0.3569],\n",
      "         ...,\n",
      "         [-0.5372, -0.2777, -0.6571,  ..., -0.4980, -0.3264, -0.5858],\n",
      "         [-0.6196,  0.1910, -2.3028,  ..., -0.9631, -0.6502,  0.4595],\n",
      "         [-1.4421,  0.2902, -2.4198,  ..., -2.4543, -1.6625, -0.6428]],\n",
      "\n",
      "        [[-1.5650, -0.0817, -1.3147,  ..., -2.3232, -1.0147, -0.2812],\n",
      "         [-1.2441, -0.1001, -2.2421,  ..., -1.2991, -2.1844, -0.1095],\n",
      "         [-1.6560, -1.3461, -1.0475,  ..., -0.8706, -1.8138, -0.0621],\n",
      "         ...,\n",
      "         [-1.0993, -0.1322, -2.1026,  ..., -1.8843, -1.6426, -0.2546],\n",
      "         [-1.3208,  0.4278, -1.7540,  ..., -1.0935, -1.2663, -0.6601],\n",
      "         [-0.6717,  0.1462, -2.7885,  ..., -2.4855, -0.9252, -0.6973]],\n",
      "\n",
      "        [[-0.9809,  0.6876, -2.0948,  ..., -2.6175, -1.1269,  0.8780],\n",
      "         [-2.3520, -0.4828, -2.3400,  ..., -0.9529, -2.0492, -0.4201],\n",
      "         [-1.7164, -0.3054, -0.9677,  ..., -1.4185, -1.9798,  1.0161],\n",
      "         ...,\n",
      "         [-0.8998,  0.1391, -1.7477,  ..., -0.8903, -1.0133, -0.4533],\n",
      "         [-0.9479,  0.0129, -3.0942,  ..., -0.8069, -0.6202, -0.7649],\n",
      "         [-1.0647, -0.4541, -2.2658,  ..., -1.3658, -1.1468, -0.6262]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Transformer: Implementaci칩n b치sica de transformadores para NLP.\n",
    "\n",
    "transformer = nn.Transformer(d_model=512, nhead=8)\n",
    "src = torch.rand(10, 32, 512)  # Secuencia de 10, batch de 32\n",
    "tgt = torch.rand(20, 32, 512)\n",
    "print(transformer(src, tgt))  # Salida transformada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.6830,  0.7343, -0.3855],\n",
      "        [-1.7161,  0.9553, -2.2004],\n",
      "        [ 0.4203,  1.4100, -0.1623]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Embedding: Convierte 칤ndices en vectores densos, 칰til en NLP.\n",
    "embedding = nn.Embedding(num_embeddings=10, embedding_dim=3)\n",
    "x = torch.tensor([1, 2, 3])\n",
    "print(embedding(x))  # Vectores densos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Capas de activaci칩n:\n",
    "Estas introducen no linealidades al modelo.\n",
    "\n",
    "- Sigmoid: Comprime valores entre 0 y 1\n",
    "- Tanh: Comprime valores entre 1 y 1\n",
    "- ReLU y LeakyReLU: Rectificadores que eliminan valores negativos.\n",
    "- Softmax: Normaliza los valores en probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 2., 0.])\n"
     ]
    }
   ],
   "source": [
    "activation = nn.ReLU()\n",
    "x = torch.tensor([-1.0, 2.0, -0.5])\n",
    "print(activation(x))  # [0.0, 2.0, 0.0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Capas auxiliares:\n",
    "Estas ayudan en el entrenamiento o procesamiento de datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.8980, 0.2642, 0.0000, 1.3410])\n"
     ]
    }
   ],
   "source": [
    "# Dropout: Apaga aleatoriamente neuronas para evitar sobreajuste.\n",
    "dropout = nn.Dropout(p=0.5)\n",
    "x = torch.rand(5)\n",
    "print(dropout(x))  # Algunos valores ser치n 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.9485, 0.8538],\n",
      "          [0.9801, 0.9988]]]])\n"
     ]
    }
   ],
   "source": [
    "# MaxPool2d: Reduce dimensionalidad seleccionando valores m치ximos en ventanas.\n",
    "pool = nn.MaxPool2d(kernel_size=2)\n",
    "x = torch.rand(1, 1, 4, 4)\n",
    "print(pool(x))  # Matriz reducida\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.3698,  0.5672,  0.5968, -0.1759],\n",
      "          [-2.6063,  1.0679, -1.6371,  0.6787],\n",
      "          [ 0.3492,  0.3053,  0.9178,  0.8488],\n",
      "          [-0.9891,  1.0175, -0.5335, -0.0377]]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# BatchNorm2d: Normaliza las activaciones para mejorar la estabilidad.\n",
    "bn = nn.BatchNorm2d(1)\n",
    "x = torch.rand(1, 1, 4, 4)\n",
    "print(bn(x))  # Salida normalizada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5359, 0.6655, 0.5985, 0.9445, 0.9084, 0.9944, 0.5636, 0.1577, 0.0906,\n",
      "         0.4134, 0.3144, 0.8716, 0.9580, 0.4522, 0.5092, 0.3494]])\n"
     ]
    }
   ],
   "source": [
    "# Flatten: Convierte datos multi-dimensionales en un vector 1D\n",
    "flatten = nn.Flatten()\n",
    "x = torch.rand(1, 1, 4, 4)\n",
    "print(flatten(x))  # Vector 1D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mamahuevaso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Datos de ejemplo: funci칩n seno\n",
    "x = np.linspace(-np.pi, np.pi, 2000, dtype=np.float32)\n",
    "y = np.sin(x, dtype=np.float32)\n",
    "\n",
    "# Convertir datos a tensores\n",
    "x_tensor = torch.tensor(x).unsqueeze(1)  # Agregar dimensi칩n para que sea (batch, 1)\n",
    "y_tensor = torch.tensor(y).unsqueeze(1)\n",
    "\n",
    "# Definir el modelo\n",
    "class SineMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1, 16),  # Capa densa: 1 entrada -> 16 neuronas\n",
    "            nn.ReLU(),         # Activaci칩n no lineal\n",
    "            nn.Linear(16, 1)   # Capa de salida: 16 neuronas -> 1 salida\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Crear el modelo\n",
    "model = SineMLP()\n",
    "\n",
    "# Funci칩n de p칠rdida y optimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Funci칩n de entrenamiento\n",
    "def train(model, x, y, epochs=1000):\n",
    "    for epoch in range(epochs):\n",
    "        # Paso hacia adelante\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        # Paso hacia atr치s\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Imprimir progreso\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "train(model, x_tensor, y_tensor, epochs=1000)\n",
    "\n",
    "# Predicci칩n y visualizaci칩n\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x_tensor).numpy()\n",
    "\n",
    "plt.plot(x, y, label=\"True (sin(x))\")\n",
    "plt.plot(x, y_pred, label=\"Predicted\", linestyle=\"dashed\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
